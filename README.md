# CS6350-Computer-Vision-TPA

# README

## Repository Structure
This repository contains codes used for the TPA-2 course project:

- `cv_grp1_tpa2_submission.ipynb`
- `extract_predictions.ipynb`
- `SampleData/` – sample images for demonstration
- `CustomData/` – custom images taken for demonstration
- `ShallowResults*/` – results generated by classical stereo methods

---

## 1. Requirements

Install the following:

Python 3.10+
Jupyter Notebook or JupyterLab  
OpenCV (cv2)  
NumPy  
Matplotlib  

For deep learning methods, check requirements of the repo cloned from.

Install packages:

```bash
pip install opencv-python numpy matplotlib torch torchvision
```

---

## 2. Dataset Setup

### KITTI Stereo Dataset

Download from:  
https://www.cvlibs.net/datasets/kitti/

You need the left and right stereo image folders.

Update your paths in the notebooks:

```yaml
left_path: "/path/to/KITTI/data_scene_flow/training/image_2/"
right_path: "/path/to/KITTI/data_scene_flow/training/image_3/"
```

Replace the placeholders with your actual dataset path.

---

## 3. Running `cv_grp1_tpa2_submission.ipynb`

This notebook includes:

- Block Matching (BM)
- Semi-Global Block Matching (SGBM)
- Edge-overlayed matching
- Intensity-gradient matching (Canny/Sobel)
- Census Transform matching
- Error metric computation

### Steps

1. Open the notebook:

```bash
jupyter notebook cv_grp1_tpa2_submission.ipynb
```

2. Update the image or dataset paths:

For DemoData:

```yaml
left_img_path: "DemoData/input_img_chc.png"
right_img_path: "DemoData/input_img_chc.png"
```

For KITTI:

```yaml
left_img_path: "/your/KITTI/left/image.png"
right_img_path: "/your/KITTI/right/image.png"
```

3. Run all cells from top to bottom.

This notebook extracts and evaluates:

- BM disparity maps  
- SGBM disparity maps  
- Error metrics (MAE, RMSE, SD, RMSE, SAD, SSD, Bad3, Bad5)  
- Visual comparisons  

Outputs will be saved in the corresponding results folders.

---

## 4. Running `extract_predictions_dtd.ipynb`

This notebook is used to run the **Dusk Till Dawn (DTD)** pretrained model on:

- the **DTD dataset** (nighttime RobotCar sequences) -  https://github.com/madhubabuv/dtd
- the **KITTI stereo dataset** - https://www.cvlibs.net/datasets/kitti/index.php

It extracts predicted disparity maps and saves them for further comparison.

### Steps

1. Open the notebook:

```bash
jupyter notebook extract_predictions.ipynb
```

2. Set the paths for pretrained DTD weights and dataset folders:

```yaml
# for dtd dataset
number_file = "datasets/robotcar/files/2014-12-16-18-44-24_numbered.txt" # custom file present in this repo, put it in appropriate folder
image_dir = "datasets/robotcar/2014-12-16-18-44-24/stereo/left" # download dtd dataset for this

# for kitti dataset
image_id = "000157_10"    # change if needed
left_path = f"/path/to/KITTI/image_2/"
right_path = f"/path/to/KITTI/image_3/"
gt_path   = f"/path/to/KITTI/gt_path"
```

3. Select the mode to run:

```yaml
file_path = "dtd_predictions.npy"      # runs DTD on nighttime RobotCar images
file_path = "dtd_predictions_own.npy"  # runs DTD on KITTI stereo pairs    
```

4. Run all cells to generate:

- DTD disparity predictions  
- Visualization plots  

---

## 6. Notes

- Always update all paths before running.
