# CS6350-Computer-Vision-TPA


# README

## Repository Structure
This repository contains two Jupyter notebooks used for the TPA-2 course project:

- cv_grp1_tpa2_submission.ipynb
- extract_predictions.ipynb
- SampleData/ – sample images for demonstration
- CustomData/ – sample images for demonstration
- ShallowResults*/ – results generated by classical stereo methods
- Additional folders used for saving outputs, plots, and metrics.

---

## 1. Requirements

Install the following:

Python 3.x  
Jupyter Notebook or JupyterLab  
OpenCV (cv2)  
NumPy  
Matplotlib  
PyTorch (required only for deep models)

Install packages:
pip install opencv-python numpy matplotlib torch torchvision

---

## 2. Dataset Setup

### KITTI Stereo Dataset

Download from:  
https://www.cvlibs.net/datasets/kitti/

You need the left and right stereo image folders.

Update your paths in the notebooks:

left_path = "/path/to/KITTI/data_scene_flow/training/image_2/"  
right_path = "/path/to/KITTI/data_scene_flow/training/image_3/"

Replace the placeholders with your actual dataset path.

---

## 3. Running cv_grp1_tpa2_submission.ipynb

This notebook includes:

- Block Matching (BM)
- Semi-Global Block Matching (SGBM)
- Edge-overlayed matching
- Intensity-gradient matching (Canny/Sobel)
- Census Transform matching
- Error metric computation

### Steps

1. Open the notebook:
jupyter notebook cv_grp1_tpa2_submission.ipynb

2. Update the image or dataset paths:

For DemoData:
left_img_path = "DemoData/input_img_chc.png"
right_img_path = "DemoData/input_img_chc.png"

For KITTI:
left_img_path = "/your/KITTI/left/image.png"
right_img_path = "/your/KITTI/right/image.png"

3. Run all cells from top to bottom.

This notebook extracts and evaluates:
- BM disparity maps
- SGBM disparity maps
- Error metrics (MAE, RMSE, SD, RMSE, SAD, SSD, Bad3, Bad5)
- Visual comparisons
Outputs will be saved in the corresponding results folders.

---

## 4. Running extract_predictions.ipynb



---

## 6. Notes

- Always update all paths before running.

